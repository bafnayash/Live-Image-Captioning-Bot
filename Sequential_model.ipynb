{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sequential_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOzXVFyM1aRZ/x1HRv4/paj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fkh2HWPM-36v","colab_type":"text"},"source":["#**Sequential Model**\n","We will execute the steps to define a sequential model that can predict a caption for the image when given image encodings and word embeddings as an input."]},{"cell_type":"markdown","metadata":{"id":"Y-eT7b6Q_MxA","colab_type":"text"},"source":["##Importing Libraries"]},{"cell_type":"code","metadata":{"id":"dCgZgithbF_2","colab_type":"code","colab":{}},"source":["from keras.models import Input, Model\n","from keras.layers import Embedding, Dense, LSTM, Dropout, BatchNormalization, add\n","from keras.utils import plot_model\n","from pickle import load, dump "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dAYYMJ8Eby_w","colab_type":"code","colab":{}},"source":["#Declaring global variables\n","max_length = 39\n","dict_size = 2355\n","target_size = (299, 299, 3)\n","embedding_size = 300"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z4W_AOhX_VW_","colab_type":"text"},"source":["##Sequential Model Architecture\n","The model consists of layers that can process image encodings as well as word embeddings. We define a dropout layer and dense layer for image encodings. We define a dropout layer and LSTM layer for word embeddings. After that we add the 2 inputs and define a dense layer on it with 'relu' activation. Finally, we apply a sigmoid layer as the output layer to generate the prediction."]},{"cell_type":"code","metadata":{"id":"WEIPdLpacS1t","colab_type":"code","colab":{}},"source":["#Processing image encodings\n","input1 = Input(shape = (2048,))\n","X1 = Dropout(0.5)(input1)\n","X1 = Dense(300, activation = 'relu')(X1)\n","\n","#Processing word embeddings\n","input2 = Input(shape = (max_length,))\n","X2 = Embedding(dict_size, embedding_size, mask_zero = True)(input2)\n","X2 = Dropout(0.5)(X2)\n","X2 = LSTM(300)(X2)\n","\n","decoder = add([X1, X2])\n","decoder = Dense(300, activation = 'relu')(decoder)\n","outputs = Dense(dict_size, activation = 'softmax')(decoder)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fDs4XHPDevTC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"status":"ok","timestamp":1595270550263,"user_tz":-330,"elapsed":708,"user":{"displayName":"Yash Bafna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPiSRImM3z8efiijxtwKRxBLI_HRQDsSXB1Zegiw=s64","userId":"13085422682742358373"}},"outputId":"ad276150-0ff7-4d83-d52c-dedd13cda2d9"},"source":["model = Model(inputs = [input1, input2], outputs = outputs)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_9 (InputLayer)            (None, 39)           0                                            \n","__________________________________________________________________________________________________\n","input_8 (InputLayer)            (None, 2048)         0                                            \n","__________________________________________________________________________________________________\n","embedding_4 (Embedding)         (None, 39, 300)      706500      input_9[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 2048)         0           input_8[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_9 (Dropout)             (None, 39, 300)      0           embedding_4[0][0]                \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 300)          614700      dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","lstm_2 (LSTM)                   (None, 300)          721200      dropout_9[0][0]                  \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 300)          0           dense_7[0][0]                    \n","                                                                 lstm_2[0][0]                     \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 300)          90300       add_2[0][0]                      \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 2355)         708855      dense_8[0][0]                    \n","==================================================================================================\n","Total params: 2,841,555\n","Trainable params: 2,841,555\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mhxoiAbgfke5","colab_type":"code","colab":{}},"source":["with open(\"embedding_matrix.pkl\", \"rb\") as f:\n","  embedding_matrix = load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uLEyIRfghYte","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":555},"executionInfo":{"status":"ok","timestamp":1595270556495,"user_tz":-330,"elapsed":1206,"user":{"displayName":"Yash Bafna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPiSRImM3z8efiijxtwKRxBLI_HRQDsSXB1Zegiw=s64","userId":"13085422682742358373"}},"outputId":"fe6e9b97-08b2-493a-f9ae-0e792e1a16e7"},"source":["#Setting the weights of the embeeding layer as the embedding matrix generated in the pre-processing phase and freezing them\n","print(model.layers[2])\n","model.layers[2].set_weights([embedding_matrix])\n","model.layers[2].trainable = False\n","summary = model.summary()\n","print(summary)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<keras.layers.embeddings.Embedding object at 0x7ff530823438>\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_9 (InputLayer)            (None, 39)           0                                            \n","__________________________________________________________________________________________________\n","input_8 (InputLayer)            (None, 2048)         0                                            \n","__________________________________________________________________________________________________\n","embedding_4 (Embedding)         (None, 39, 300)      706500      input_9[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 2048)         0           input_8[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_9 (Dropout)             (None, 39, 300)      0           embedding_4[0][0]                \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 300)          614700      dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","lstm_2 (LSTM)                   (None, 300)          721200      dropout_9[0][0]                  \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 300)          0           dense_7[0][0]                    \n","                                                                 lstm_2[0][0]                     \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 300)          90300       add_2[0][0]                      \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 2355)         708855      dense_8[0][0]                    \n","==================================================================================================\n","Total params: 2,841,555\n","Trainable params: 2,135,055\n","Non-trainable params: 706,500\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TsrXD480h0e3","colab_type":"code","colab":{}},"source":["model.compile(optimizer = 'adam', loss = 'categorical_crossentropy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uy2wnSchjGtL","colab_type":"code","colab":{}},"source":["#Saving the sequential model as a json file and saving the weigths of the model as '.h5' file so that we can use them when we finally train the sequential model\n","model_json = model.to_json()\n","with open(\"model.json\", \"w\") as f:\n","  f.write(model_json)\n","model.save_weights(\"model.h5\")"],"execution_count":null,"outputs":[]}]}